{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports and iPython settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Full library imports\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.ndimage as scimg\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.color as skc\n",
    "\n",
    "# Selective library imports\n",
    "from os import listdir, getcwd\n",
    "from pylab import rcParams\n",
    "from numpy import histogram, interp, cumsum, diff\n",
    "from os.path import isfile, join\n",
    "from matplotlib import cm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.ndimage import imread\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "#ipython setting\n",
    "rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To get $ f: D \\rightarrow \\left[ 0, M\\right]$, simply scale the cumulative distribution function $H_f \\left( v \\right)$ with the factor M. This gives: $\\psi = M \\cdot H_f \\left( v \\right)$\n",
    "\n",
    "2. The following program  takes in a simple image and runs a histogram equalization algorithm. After this the original picture and the equalised picture are shown together with their histograms. The image is read with scipy ensuring it is read into memory as a uint8 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BINS = 100\n",
    "IM_SIZE = 255\n",
    "\n",
    "def histogramEqualization(f, bins=BINS):\n",
    "    his, be = histogram(f, range=(0,IM_SIZE), bins=bins)\n",
    "    hist = his.astype(float)/sum(his)\n",
    "    return interp(f, be[1:], cumsum(hist)), his, be\n",
    "\n",
    "def get_image_set(path):\n",
    "    \n",
    "    img_loc = getcwd() + '/' + path + '/'\n",
    "    img_list = [img_loc + f for f in listdir(img_loc)]\n",
    "    \n",
    "    return img_list\n",
    "\n",
    "def eq_img(dataset):\n",
    "    \n",
    "    imgset = get_image_set('different_angles' + dataset)\n",
    "    imgset_size = len(imgset)\n",
    "    \n",
    "    fig, axarr = plt.subplots(imgset_size, 4)\n",
    "    \n",
    "    for i in range(imgset_size):\n",
    "        \n",
    "        f = imread(imgset[i])\n",
    "        f_eq, his_img, be_img = histogramEqualization(f)\n",
    "        his_eq, be_eq = histogram(f_eq, range=(0,1), bins=BINS)\n",
    "        \n",
    "        axarr[i, 0].imshow(f)\n",
    "        axarr[i, 1].bar((be_img[:-1] + be_img[1:]) / 2, his_img, align='center', width=diff(be_img))\n",
    "        axarr[i, 2].imshow(f_eq)\n",
    "        axarr[i, 3].bar((be_eq[:-1] + be_eq[1:]) / 2, his_eq, align='center', width=diff(be_eq))\n",
    "        axarr[i, 0].axis('off')\n",
    "        axarr[i, 1].axis('off')\n",
    "        axarr[i, 2].axis('off')\n",
    "        axarr[i, 3].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def single_im_eq(file):\n",
    "    \n",
    "    #Read figure and equalise\n",
    "    img = scimg.imread(file)\n",
    "    img_eq, his, be = histogramEqualization(img)\n",
    "\n",
    "    f, axarr = plt.subplots(2, 2)\n",
    "\n",
    "    #plot histogram of original data\n",
    "    axarr[1, 0].bar((be[:-1] + be[1:]) / 2, his, align='center', width=diff(be))\n",
    "    axarr[1, 0].set_xticks([be[x] for x in range(0, len(be), int(BINS/10))])\n",
    "\n",
    "    # Show original image\n",
    "    axarr[0, 0].imshow(img, cmap='gray')\n",
    "\n",
    "    #plot histogram of equalized image\n",
    "    his, be = histogram(img_eq, range=(0,1), bins=BINS)\n",
    "    axarr[1, 1].bar((be[:-1] + be[1:]) / 2, his, align='center', width=diff(be))\n",
    "    axarr[1, 1].set_xticks([be[x] for x in range(0, len(be), int(BINS/10))])\n",
    "\n",
    "    # Show equalized image\n",
    "    axarr[0, 1].imshow(img_eq, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  above code defines functions which are run below, for seperation of definition and execution.\n",
    "It is clear from the following plots that very high contrast images are difficult targets for histogram equalisation with largge gaps appearing in the equalised histograms. The \"desk\" dataset shows that histogram equalisation can be very effective in making images look alike with respect to contrast, however dark patches in the original image may also make this a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test histogram equalization for a single image\n",
    "single_im_eq(\"cameraman1.png\")\n",
    "\n",
    "# Test histogram equalization for an entire dataset\n",
    "# First two image sets courtesy of: http://aloi.science.uva.nl/\n",
    "# Third image set: https://rgbd-dataset.cs.washington.edu/dataset/\n",
    "eq_img(\"duck\")\n",
    "eq_img(\"tea\")\n",
    "eq_img(\"desk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin color detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plot a 3d-scatter plot of RGB values of skin and non-skin colors. Plots the points corresponding to skin color in green and the points corresponding to non-skin color in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Amount of samples taken in plotting 3D scatter\n",
    "SAMPLES = 500\n",
    "\n",
    "# Randomly takes n points from a numpy array\n",
    "def sample(ar, n):\n",
    "\n",
    "    i = 0\n",
    "    sample = 0\n",
    "    # Create empty holder array\n",
    "    samples = np.zeros(n)\n",
    "\n",
    "    while i < len(ar) and sample < n:\n",
    "\n",
    "        # 50% chance to select item, not critical in this\n",
    "        # implementation (just used for speeding up program)\n",
    "        if random.random() > .5:\n",
    "\n",
    "            samples[sample] = ar[i]\n",
    "            sample += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return samples\n",
    "\n",
    "#Read images\n",
    "# f = imread('SkinColor/FacePhoto/0520962400.jpg')\n",
    "# m = imread('SkinColor/GroundT_FacePhoto/0520962400.png')\n",
    "f = imread('SkinColor/FamilyPhoto/buck_family.jpg')\n",
    "m = imread('SkinColor/GroundT_FamilyPhoto/buck_family.png')\n",
    "\n",
    "skincolors = f[m[:,:,0]==255]\n",
    "nonskincolors = f[m[:,:,0]==0]\n",
    "\n",
    "# Take a selection of SAMPLES points to plot in 3D plot for\n",
    "# both skin- and non-skin colors\n",
    "x, y, z = np.split(skincolors, 3, 1)\n",
    "x = sample(x, SAMPLES)\n",
    "y = sample(y, SAMPLES)\n",
    "z = sample(z, SAMPLES)\n",
    "\n",
    "t, u, v = np.split(nonskincolors, 3, 1)\n",
    "t = sample(x, SAMPLES)\n",
    "u = sample(y, SAMPLES)\n",
    "v = sample(z, SAMPLES)\n",
    "\n",
    "# 3D scatter plot of randomly selected points\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, s=30, c='green')\n",
    "ax.scatter(t, u, v, s=30, c='red')\n",
    "ax.set_xlabel('R')\n",
    "ax.set_ylabel('G')\n",
    "ax.set_zlabel('B')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier for use with skin color detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert image to lab color convention taking only the ab dimensions\n",
    "f_lab = skc.rgb2lab(f)[::, ::, 1::]\n",
    "# Extract skin- and non-skin colors from image data\n",
    "sc_lab = f_lab[m[:,:,0]==255]\n",
    "nsc_lab = f_lab[m[:,:,0]==0]\n",
    "\n",
    "# Scatter plot of a selection of skin and non-skin colors\n",
    "plt.scatter(sc_lab[::25, 0], sc_lab[::25, 1], s=1, marker=',', color='green')\n",
    "plt.scatter(nsc_lab[::25, 0], nsc_lab[::25, 1], s=1, marker=',', color='red')\n",
    "plt.xlabel(\"a\")\n",
    "plt.ylabel(\"b\")\n",
    "plt.show()\n",
    "\n",
    "# Combine the skin and non-skin color feature vectors into a single item\n",
    "# And do this for the classes corresponding to the colors\n",
    "color = np.vstack((sc_lab, nsc_lab))\n",
    "target = np.concatenate((np.ones(len(sc_lab)),np.zeros(len(nsc_lab))))\n",
    "\n",
    "# Take half the data to learn the classifier and use the other half to\n",
    "# test it\n",
    "learn_color = color[1::2]\n",
    "test_color = color[0::2]\n",
    "learn_target = target[1::2]\n",
    "test_target = target[0::2]\n",
    "logregr = LogisticRegressionCV()\n",
    "logregr.fit(learn_color, learn_target)\n",
    "\n",
    "print(\"Score of logistic regression:\")\n",
    "print(logregr.score(test_color, test_target))\n",
    "\n",
    "image_colors = f_lab.reshape((-1,2))\n",
    "predict_skin = logregr.predict(image_colors).reshape(f_lab.shape[:2])\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(f)\n",
    "plt.subplot(122)\n",
    "plt.imshow(predict_skin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a generally applicable classifier we need to train it with more than just one picture. Also, using the same picture we trained with as a test is questionable to say the least. Though the princimple has been proven the need for more training data is necessary.\n",
    "\n",
    "In the following program a loop is called for all pictures in the directory and then they are used for training the classifier. A subset of pixels is used to reduce the large amount of data. Then the classifier is tested on another folder of images which will check the validity of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train data path\n",
    "REL_PATH_FACE = 'SkinColor/FacePhoto/'\n",
    "REL_PATH_MASK = 'SkinColor/GroundT_FacePhoto/'\n",
    "\n",
    "# Test data path\n",
    "REL_PATH_FAM = 'SkinColor/FamilyPhoto/'\n",
    "\n",
    "# Classifier parameters:\n",
    "NNB = 5\n",
    "MAX_DEPTH = 10\n",
    "ALPHA = 1\n",
    "\n",
    "def read_image(file, sample_interval):\n",
    "    \n",
    "    f = imread(REL_PATH_FACE + file)\n",
    "    # Only take .jpg and .jpeg files\n",
    "    if file[-4:] == \".jpg\":\n",
    "        m = imread(REL_PATH_MASK + file[:-4] + '.png')\n",
    "    elif file[-4:] == \"jpeg\":\n",
    "        m = imread(REL_PATH_MASK + file[:-4] + 'png')\n",
    "    else:\n",
    "        return np.zeros([1, 1]), np.zeros([1, 1])\n",
    "        \n",
    "    # Convert image to lab color convention taking only the ab dimensions\n",
    "    # and every 100th element to reduce sheer amount of data\n",
    "    f_lab = skc.rgb2lab(f)[::, ::sample_interval, 1::]\n",
    "    # Extract skin- and non-skin colors from image data\n",
    "    sc_lab = f_lab[m[:, ::sample_interval, 0]==255]\n",
    "    nsc_lab = f_lab[m[:, ::sample_interval, 0]==0]\n",
    "        \n",
    "    color = np.vstack((sc_lab, nsc_lab))\n",
    "    target = np.concatenate((np.ones(len(sc_lab)),np.zeros(len(nsc_lab))))\n",
    "    \n",
    "    return color, target\n",
    "    \n",
    "# Reads image data from current directory with hierarchy as given in \n",
    "# the exercise.\n",
    "def read_image_folder(sample_interval):\n",
    "    \n",
    "    mypath = getcwd()\n",
    "    original = mypath + '/' + REL_PATH_FACE\n",
    "    original_list = [f for f in listdir(original)]\n",
    "    original_list.sort()\n",
    "    \n",
    "    # Set up initial data vector to whcih other will be appended\n",
    "    data_vector, target_vector = read_image(original_list[1], sample_interval)\n",
    "    \n",
    "    for file in original_list[1:]:\n",
    "        \n",
    "        c, t = read_image(file, sample_interval)\n",
    "        \n",
    "        if c.all() == 0 and t.all() == 0:\n",
    "            continue\n",
    "        \n",
    "        data_vector = np.concatenate((data_vector, c))\n",
    "        target_vector = np.concatenate((target_vector, t))\n",
    "    \n",
    "    return data_vector, target_vector\n",
    "\n",
    "def read_random_image(dataset):\n",
    "    \n",
    "    if dataset == \"family\":\n",
    "        dataset = REL_PATH_FAM\n",
    "    elif dataset == \"face\":\n",
    "        dataset = REL_PATH_FACE\n",
    "    \n",
    "    mypath = getcwd()\n",
    "    img_loc = mypath + '/' + dataset\n",
    "    img_list = [f for f in listdir(img_loc)]\n",
    "    \n",
    "    img_index = random.randint(0, len(img_list) - 1)\n",
    "    \n",
    "    return imread(dataset + img_list[img_index]) \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "class skin_color_classifier:\n",
    "    \n",
    "    def __init__(self, data, target, classifier=\"logreg\",\n",
    "                 max_depth = MAX_DEPTH, nnb=NNB, alpha=ALPHA):\n",
    "        \n",
    "        if classifier == \"logreg\":\n",
    "            self.classifier = LogisticRegressionCV()\n",
    "        elif classifier == \"tree\":\n",
    "            self.classifier = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        elif classifier == \"KNNB\":\n",
    "            self.classifier = KNeighborsClassifier(nnb)\n",
    "        elif classifier == \"MLP\":\n",
    "            self.classifier = MPLClassifier(alpha=1)\n",
    "        self.classifier_type = classifier\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        self.classifier.fit(self.data, self.target)\n",
    "        \n",
    "    def predict(self, image, plot=\"true\"):\n",
    "        \n",
    "        # Take only ab dimensions of LAB color space and reshape data\n",
    "        image_colors = skc.rgb2lab(image)[::, ::, 1::].reshape((-1, 2))\n",
    "        prediction = self.classifier.predict(image_colors).reshape(image.shape[:2])\n",
    "        \n",
    "        if plot:\n",
    "            self.plot_image(image, prediction)\n",
    "        \n",
    "        \n",
    "    def plot_image(self, image, prediction):\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(prediction)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# Get training data\n",
    "clrs, trgts = read_image_folder(100)\n",
    "\n",
    "# Create classifiers and train using training data\n",
    "logregr = skin_color_classifier(clrs, trgts)\n",
    "logregr.train()\n",
    "print(\"Logistic regression trained.\")\n",
    "tree = skin_color_classifier(clrs, trgts, \"tree\", max_depth=MAX_DEPTH)\n",
    "tree.train()\n",
    "print(\"Tree classifier trained with %s max depth trained.\" % (MAX_DEPTH))\n",
    "KNNB = skin_color_classifier(clrs, trgts, \"KNNB\", nnb=NNB)\n",
    "KNNB.train()\n",
    "print(\"K nearest neghbor classifier trained with %s nearest neighbors trained.\" % (NNB))\n",
    "MLP = skin_color_classifier(clrs, trgts, \"KNNB\", alpha=ALPHA)\n",
    "MLP.train()\n",
    "print(\"Multi-layer perceptron classifier with alpha = %s trained.\" % (ALPHA))\n",
    "\n",
    "print(\"Done training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section of code it is possible to test the quality of a selection of classifiers. By running the loop an image can be loaded from disk and will be checked with the chosen classifier. The classifiers are all trained in the previous section and can be retrained with different parameters by setting these in the constants defined below and running the above section again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NNB = 5\n",
    "MAX_DEPTH = 10\n",
    "ALPHA = 1\n",
    "\n",
    "# Setup initial source (family or face photo's)\n",
    "source = 'face'\n",
    "\n",
    "# As long as user keeps asking for images, keeps classifying them\n",
    "#     (input = \"classifier type\")\n",
    "# When done enter 'q'\n",
    "while True:\n",
    "    inp = input()\n",
    "    if inp == 'family' or inp == 'face':\n",
    "        source = inp\n",
    "    elif inp == 'logreg':\n",
    "        test_img = read_random_image(source)\n",
    "        logregr.predict(test_img)\n",
    "    elif inp == 'tree':\n",
    "        test_img = read_random_image(source)\n",
    "        tree.predict(test_img)\n",
    "    elif inp == 'KNNB':\n",
    "        test_img = read_random_image(source)\n",
    "        KNNB.predict(test_img)\n",
    "    elif inp == 'MLP':\n",
    "        test_img = read_random_image(source)\n",
    "        MLP.predict(test_img)\n",
    "    elif inp == 'q':\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although no extensive formal testing has been conducted, it can easily be seen that the classifier has trouble with colors that are close to skin color. For example; walls, sand or clothing is frequently misclassified. Also the logistic regression classifier seems to have an obsession with red in some cases. The way it has currently been set up, the tree and KNNB  classifiers seem to perform better than simple logistic regression though as suggested, contextual information (surronding pixels) might help with getting more accurate results. The absolute winner of the classifiers I tried seems to be the multi-layer perceptron neural network classifier, face features are very clear and misclassification seems minimal in comparison to the other classifiers.\n",
    "Running the classifiers on the other dataset (family) has varying results, some pictures are classified with near perfect accuracy while some pictures are completele misclassified.\n",
    "I also tried getting a gaussion classifier and an SVM to work but unfortunately this either crashed or refused to run altogether."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
